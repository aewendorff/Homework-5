)
# --- Plot --- #
meanweight_plot <- fishCSV_filt_summary %>%
ggplot(aes(x = Year, y = mean_weight_g, color = Species)) +
geom_line() +
geom_point() +
scale_fill_brewer(palette = "Set2") +
labs(
title = "Temporal Change of Mean Weight Across Great Lakes Fish Species",
x = "Mean Weight (g)",
y = "Year") +
theme_minimal(base_size = 14) +
theme(plot.title = element_text(face = "bold", margin = margin(b = 20)),
axis.title.x = element_text(margin = margin(t = 20)),
axis.title.y = element_text(margin = margin(r = 20)),
)
print(meanweight_plot)
# --- Export --- #
write.csv(fishCSV_filt, "Outputs/fish_filtered.csv")
write.csv(fishCSV_filt_summary, "Outputs/fish_filtered_summary.csv")
write.csv(fishCSV_filt, "Outputs/length_count.csv")
###################
### OBJECTIVE 4 ###
###################
multiple_files <- list.files(path = "Data/Multiple_files", full.names = TRUE) #List all of the files in the folder we are calling
View(multiple_files) #Viewing the files to make sure that the data was called in correctly
multiple_list <- lapply(multiple_files, read.csv) #Read the files in the Multiple_files Folder
multiple_df <- dplyr::bind_rows(multiple_list) #Combine all of the files' data into one dataframe titles "multiple_df"
View(multiple_df) (edited)
meanweight_plot <- fishCSV_filt_summary %>%
ggplot(aes(x = Year, y = mean_weight_g, color = Species)) +
geom_line() +
geom_point() +
scale_fill_brewer(palette = "Set2") +
labs(
title = "Temporal Change of Mean Weight Across Great Lakes Fish Species",
x = "Mean Weight (g)",
y = "Year") +
theme_minimal(base_size = 14) +
theme(plot.title = element_text(face = "bold", margin = margin(b = 20)),
axis.title.x = element_text(margin = margin(t = 20)),
axis.title.y = element_text(margin = margin(r = 20)),
)
print(meanweight_plot)
write.csv(fishCSV_filt, "Outputs/fish_filtered.csv")
write.csv(fishCSV_filt_summary, "Outputs/fish_filtered_summary.csv")
write.csv(fishCSV_filt, "Outputs/length_count.csv")
multiple_files <- list.files(path = "Data/Multiple_files", full.names = TRUE) #List all of the files in the folder we are calling
View(multiple_files) #Viewing the files to make sure that the data was called in correctly
multiple_list <- lapply(multiple_files, read.csv) #Read the files in the Multiple_files Folder
multiple_df <- dplyr::bind_rows(multiple_list) #Combine all of the files' data into one dataframe titles "multiple_df"
View(multiple_df) (edited)
multiple_files <- list.files(path = "Data/Multiple_files", full.names = TRUE) #List all of the files in the folder we are calling
View(multiple_files) #Viewing the files to make sure that the data was called in correctly
multiple_list <- lapply(multiple_files, read.csv) #Read the files in the Multiple_files Folder
multiple_df <- dplyr::bind_rows(multiple_list) #Combine all of the files' data into one dataframe titles "multiple_df"
View(multiple_df)
print(multiple_files)
multiple_files <- list.files(path = "Data/Multiple_Files", full.names = TRUE) #List all of the files in the folder we are calling
View(multiple_files) #Viewing the files to make sure that the data was called in correctly
multiple_list <- lapply(multiple_files, read.csv) #Read the files in the Multiple_files Folder
multiple_df <- dplyr::bind_rows(multiple_list) #Combine all of the files' data into one dataframe titles "multiple_df"
View(multiple_df)
##################
### HOMEWORK 5 ###
#################
# Authors: Aubrey Wendorff, Rebekkah LaBlue, & Victoria Salerno
# Concepts: Uploading, Wrangling, & Exporting Data
# Due: October 6, 2025
################
### STEP UP ###
###############
library(dplyr)
library(readxl)
library(writexl)
library(magrittr)
library(ggplot2)
###################
### OBJECTIVE 1 ###
###################
# Open files and
fishCSV <- read.csv("Data/fish.csv", stringsAsFactors = FALSE) # force all variables to strings, next manually assign as factors
fishCSV <- fishCSV %>%
mutate(across(c(Species, Lake, Year), as.factor)) # as.factor = manually assign factor categorization to non-continuous variables
str(fishCSV) # check variabels are in proper order
head(fishXL, 5) # show only first 5 columns
fishXL <- read_excel("Data/fish.xlsx")
fishXL <- fishXL %>%
mutate(across(c(Species, Lake, Year), as.factor))
str(fishXL)
head(fishXL, 5)
fishRDS <- readRDS("Data/fish.rds")
fishRDS <- fishRDS %>%
mutate(across(c(Species, Lake, Year), as.factor))
str(fishRDS)
head(fishRDS, 5)
###################
### OBJECTIVE 2 ###
###################
fish_export <- fishCSV # choose a dataset from above, rename for clarity in next step
write.csv(fish_export, "Outputs/fish_export.csv")
saveRDS(fish_export, "Outputs/fish_export.rds")
write_xlsx(fish_export, "Outputs/fish_export.xlsx")
###################
### OBJECTIVE 3 ###
###################
# --- Filter, Select --- #
fishCSV_filt <- fishCSV %>%
filter(Species %in% c("Walleye", "Yellow Perch", "Smallmouth Bass"), # filter by species of interest
Lake %in% c("Erie", "Michigan")) %>% # filter by lakes of interest
select(Species, Lake, Year, Length_cm, Weight_g) # select, retain only these columns in filtered df
# --- Create Variables --- #
fishCSV_filt <- fishCSV_filt %>%
mutate(
Length_mm = Length_cm * 10, # create new column from base with new specification
Length_group = cut(
Length_mm, # use values from this column on which to apply cutoff/binning criteria
breaks = c(0, 200, 400, 600, Inf), # create 5 breaks = 4 bins
labels = c("≤200", "200–400", "400–600", "≥600") # name bins
)
)
length_counts <- fishCSV_filt %>%
count(Species, Length_group) # tally counts per species, newly created length grouping
# --- Summarize --- #
fishCSV_filt_summary <- fishCSV_filt %>%
group_by(Species, Year) %>% # grouping to summarize stats by multiple criteria
summarise(
mean_weight_g = mean(Weight_g, na.rm = TRUE), # new column with mean fx applied to base data
median_weight_g = median(Weight_g, na.rm = TRUE), # new colunn with median fx applied to base data
sample_size = n(), # show counts/sample size for each grouping by above criteria
.groups = "drop" # remove grouping bins from the dataframe once summaries have been caluclated
)
# --- Plot --- #
meanweight_plot <- fishCSV_filt_summary %>%
ggplot(aes(x = Year, y = mean_weight_g, color = Species)) +
geom_line() +
geom_point() +
scale_fill_brewer(palette = "Set2") +
labs(
title = "Temporal Change of Mean Weight Across Great Lakes Fish Species",
x = "Mean Weight (g)",
y = "Year") +
theme_minimal(base_size = 14) +
theme(plot.title = element_text(face = "bold", margin = margin(b = 20)),
axis.title.x = element_text(margin = margin(t = 20)),
axis.title.y = element_text(margin = margin(r = 20)),
)
print(meanweight_plot)
# --- Export --- #
write.csv(fishCSV_filt, "Outputs/fish_filtered.csv")
write.csv(fishCSV_filt_summary, "Outputs/fish_filtered_summary.csv")
write.csv(fishCSV_filt, "Outputs/length_count.csv")
###################
### OBJECTIVE 4 ###
###################
multiple_files <- list.files(path = "Data/Multiple_Files", full.names = TRUE) #List all of the files in the folder we are calling
View(multiple_files) #Viewing the files to make sure that the data was called in correctly
multiple_list <- lapply(multiple_files, read.csv) #Read the files in the Multiple_files Folder
multiple_df <- dplyr::bind_rows(multiple_list) #Combine all of the files' data into one dataframe titles "multiple_df"
View(multiple_df)
###################
### OBJECTIVE 5 ###
###################
# --- Setup: load base parallel, read data ---#
library(parallel)
fish <- read.csv("Data/fish_bootstrap_parallel_computing.csv")
species <- unique(fish$Species)            #list of species to loop over
# --- Bootstrap function in Base R ---#
boot_mean <- function(species_name, n_boot = 10000, sample_size = 200) {
x <- fish$Weight_g[fish$Species == species_name] # Pull the Weigh_g vector for just this species
# n_boot = 10000 resamples WITH replacement; compute the mean each time
# sample_size = how many fish per species we want to pull
means <- replicate(n_boot, mean(sample(x, size = sample_size, replace = TRUE)))  # replicate(...) returns a numeric vector of bootstrap means
mean(means) # Returns the average of the bootstrap means
}
# --- SERIAL ---#
t_serial <- system.time({                   # time the whole serial run
res_serial <- lapply(                     # loop over species in the main R process
species,                                # input: vector of species names
boot_mean,                              # function to apply
n_boot = 10000,                         # number of bootstrap resamples per species
sample_size = 200                       # bootstrap sample size
)
})
head(res_serial)
# --- PARALLEL --- #
n_cores <- max(1, detectCores() - 1)        # use all but one core
cl <- makeCluster(n_cores)                  # start worker processes
clusterSetRNGStream(cl, iseed = 123)        # make random numbers reproducible across workers
# Send needed objects to workers (function + data + species vector)
clusterExport(cl, varlist = c("fish", "boot_mean", "species"), envir = environment())
t_parallel <- system.time({                 # time the parallel run
res_parallel <- parLapply(                # same API as lapply(), but across workers
cl,                                     # the cluster
species,                                # each worker gets one species (or more)
boot_mean,                              # function to run
n_boot = 10000,                           # same bootstrap settings as serial
sample_size = 200
)
})
stopCluster(cl)                             # always stop the cluster when done
# --- Compare runtimes & show speedup --------------------------------------
# Extract elapsed time and compute speedup = serial / parallel
elapsed_serial   <- unname(t_serial["elapsed"])
elapsed_parallel <- unname(t_parallel["elapsed"])
speedup <- elapsed_serial / elapsed_parallel
cat("Serial elapsed (s):   ", round(elapsed_serial, 3), "\n")
cat("Parallel elapsed (s): ", round(elapsed_parallel, 3), " using ", n_cores, " cores\n", sep = "")
cat("Speedup:               ", round(speedup, 2), "x\n", sep = "")
file.info("Outputs/fish_export.csv)
file.info("Outputs/fish_export.csv")
file.info(c("Output/fish_export.csv", "Outputs/fish_export.rds", "Outputs/fish_export.xlsx"))$size)
file.info(c("Output/fish_export.csv", "Outputs/fish_export.rds", "Outputs/fish_export.xlsx"))$size
##################
### HOMEWORK 5 ###
#################
# Authors: Aubrey Wendorff, Rebekkah LaBlue, & Victoria Salerno
# Concepts: Uploading, Wrangling, & Exporting Data
# Due: October 6, 2025
################
### STEP UP ###
###############
library(dplyr)
library(readxl)
library(writexl)
library(magrittr)
library(ggplot2)
###################
### OBJECTIVE 1 ###
###################
# Open files and
fishCSV <- read.csv("Data/fish.csv", stringsAsFactors = FALSE) # force all variables to strings, next manually assign as factors
fishCSV <- fishCSV %>%
mutate(across(c(Species, Lake, Year), as.factor)) # as.factor = manually assign factor categorization to non-continuous variables
str(fishCSV) # check variabels are in proper order
head(fishXL, 5) # show only first 5 columns
head(fishXL, 5) # show only first 5 columns
# Open files and
fishCSV <- read.csv("Data/fish.csv", stringsAsFactors = FALSE) # force all variables to strings, next manually assign as factors
fishCSV <- fishCSV %>%
mutate(across(c(Species, Lake, Year), as.factor)) # as.factor = manually assign factor categorization to non-continuous variables
str(fishCSV) # check variabels are in proper order
fishXL <- read_excel("Data/fish.xlsx")
fishXL <- fishXL %>%
mutate(across(c(Species, Lake, Year), as.factor))
str(fishXL)
head(fishXL, 5) # show only first 5 columns
fishRDS <- readRDS("Data/fish.rds")
fishRDS <- fishRDS %>%
mutate(across(c(Species, Lake, Year), as.factor))
str(fishRDS)
head(fishRDS, 5)
fish_export <- fishCSV # choose a dataset from above, rename for clarity in next step
write.csv(fish_export, "Outputs/fish_export.csv")
saveRDS(fish_export, "Outputs/fish_export.rds")
write_xlsx(fish_export, "Outputs/fish_export.xlsx")
file.info(c("Output/fish_export.csv", "Outputs/fish_export.rds", "Outputs/fish_export.xlsx"))$size
file.info(c("Output/fish_export", "Outputs/fish_export.rds", "Outputs/fish_export.xlsx"))$size
file.info(c("Output/fish_export", "Outputs/fish_export.rds", "Outputs/fish_export.xlsx"))$size
file.info("Output/fish_export")
file.info("Output/fish_export")$size
fish_export <- fishCSV # choose a dataset from above, rename for clarity in next step
write.csv(fish_export, "Outputs/fish_export.csv")
saveRDS(fish_export, "Outputs/fish_export.rds")
write_xlsx(fish_export, "Outputs/fish_export.xlsx")
file.info(c("Outputs/fish_export", "Outputs/fish_export.rds", "Outputs/fish_export.xlsx"))$size
##################
### HOMEWORK 5 ###
#################
# Authors: Aubrey Wendorff, Rebekkah LaBlue, & Victoria Salerno
# Concepts: Uploading, Wrangling, & Exporting Data
# Due: October 6, 2025
################
### STEP UP ###
###############
library(dplyr)
library(readxl)
library(writexl)
library(magrittr)
library(ggplot2)
###################
### OBJECTIVE 1 ###
###################
fishCSV <- read.csv("Data/fish.csv", stringsAsFactors = FALSE) # force all variables to strings, next manually assign as factors
fishCSV <- fishCSV %>%
mutate(across(c(Species, Lake, Year), as.factor)) # as.factor = manually assign factor categorization to non-continuous variables
str(fishCSV) # check variabels are in proper order
fishXL <- read_excel("Data/fish.xlsx")
fishXL <- fishXL %>%
mutate(across(c(Species, Lake, Year), as.factor))
str(fishXL)
head(fishXL, 5) # show only first 5 columns
fishRDS <- readRDS("Data/fish.rds")
fishRDS <- fishRDS %>%
mutate(across(c(Species, Lake, Year), as.factor))
str(fishRDS)
head(fishRDS, 5)
###################
### OBJECTIVE 2 ###
###################
fish_export <- fishCSV # choose a dataset from above, rename for clarity in next step
write.csv(fish_export, "Outputs/fish_export.csv")
saveRDS(fish_export, "Outputs/fish_export.rds")
write_xlsx(fish_export, "Outputs/fish_export.xlsx")
file.info(c("Outputs/fish_export.csv", "Outputs/fish_export.rds", "Outputs/fish_export.xlsx"))$size
###################
### OBJECTIVE 3 ###
###################
# --- Filter, Select --- #
fishCSV_filt <- fishCSV %>%
filter(Species %in% c("Walleye", "Yellow Perch", "Smallmouth Bass"), # filter by species of interest
Lake %in% c("Erie", "Michigan")) %>% # filter by lakes of interest
select(Species, Lake, Year, Length_cm, Weight_g) # select, retain only these columns in filtered df
# --- Create Variables --- #
fishCSV_filt <- fishCSV_filt %>%
mutate(
Length_mm = Length_cm * 10, # create new column from base with new specification
Length_group = cut(
Length_mm, # use values from this column on which to apply cutoff/binning criteria
breaks = c(0, 200, 400, 600, Inf), # create 5 breaks = 4 bins
labels = c("≤200", "200–400", "400–600", "≥600") # name bins
)
)
length_counts <- fishCSV_filt %>%
count(Species, Length_group) # tally counts per species, newly created length grouping
# --- Summarize --- #
fishCSV_filt_summary <- fishCSV_filt %>%
group_by(Species, Year) %>% # grouping to summarize stats by multiple criteria
summarise(
mean_weight_g = mean(Weight_g, na.rm = TRUE), # new column with mean fx applied to base data
median_weight_g = median(Weight_g, na.rm = TRUE), # new colunn with median fx applied to base data
sample_size = n(), # show counts/sample size for each grouping by above criteria
.groups = "drop" # remove grouping bins from the dataframe once summaries have been caluclated
)
# --- Plot --- #
meanweight_plot <- fishCSV_filt_summary %>%
ggplot(aes(x = Year, y = mean_weight_g, color = Species)) +
geom_line() +
geom_point() +
scale_fill_brewer(palette = "Set2") +
labs(
title = "Temporal Change of Mean Weight Across Great Lakes Fish Species",
x = "Mean Weight (g)",
y = "Year") +
theme_minimal(base_size = 14) +
theme(plot.title = element_text(face = "bold", margin = margin(b = 20)),
axis.title.x = element_text(margin = margin(t = 20)),
axis.title.y = element_text(margin = margin(r = 20)),
)
print(meanweight_plot)
# --- Export --- #
write.csv(fishCSV_filt, "Outputs/fish_filtered.csv")
write.csv(fishCSV_filt_summary, "Outputs/fish_filtered_summary.csv")
write.csv(fishCSV_filt, "Outputs/length_count.csv")
###################
### OBJECTIVE 4 ###
###################
multiple_files <- list.files(path = "Data/Multiple_Files", full.names = TRUE) #List all of the files in the folder we are calling
View(multiple_files) #Viewing the files to make sure that the data was called in correctly
multiple_list <- lapply(multiple_files, read.csv) #Read the files in the Multiple_files Folder
multiple_df <- dplyr::bind_rows(multiple_list) #Combine all of the files' data into one dataframe titles "multiple_df"
View(multiple_df)
##################
### HOMEWORK 5 ###
#################
# Authors: Aubrey Wendorff, Rebekkah LaBlue, & Victoria Salerno
# Concepts: Uploading, Wrangling, & Exporting Data
# Due: October 6, 2025
################
### STEP UP ###
###############
library(dplyr)
library(readxl)
library(writexl)
library(magrittr)
library(ggplot2)
###################
### OBJECTIVE 1 ###
###################
fishCSV <- read.csv("Data/fish.csv", stringsAsFactors = FALSE) # force all variables to strings, next manually assign as factors
fishCSV <- fishCSV %>%
mutate(across(c(Species, Lake, Year), as.factor)) # as.factor = manually assign factor categorization to non-continuous variables
str(fishCSV) # check variabels are in proper order
fishXL <- read_excel("Data/fish.xlsx")
fishXL <- fishXL %>%
mutate(across(c(Species, Lake, Year), as.factor))
str(fishXL)
head(fishXL, 5) # show only first 5 columns
fishRDS <- readRDS("Data/fish.rds")
fishRDS <- fishRDS %>%
mutate(across(c(Species, Lake, Year), as.factor))
str(fishRDS)
head(fishRDS, 5)
###################
### OBJECTIVE 2 ###
###################
fish_export <- fishCSV # choose a dataset from above, rename for clarity in next step
write.csv(fish_export, "Outputs/fish_export.csv")
saveRDS(fish_export, "Outputs/fish_export.rds")
write_xlsx(fish_export, "Outputs/fish_export.xlsx")
file.info(c("Outputs/fish_export.csv", "Outputs/fish_export.rds", "Outputs/fish_export.xlsx"))$size
#The CSV is 14423 bytes, the rds is 2857 bytes, and the excel file is 14312 bytes.
#The best for sharing is the csv file because it is plain text and is more easily readable by various softwares than the excel file.
#The best for compact storage is the rds file because it takes up the smallest space (2857 bytes).
###################
### OBJECTIVE 3 ###
###################
# --- Filter, Select --- #
fishCSV_filt <- fishCSV %>%
filter(Species %in% c("Walleye", "Yellow Perch", "Smallmouth Bass"), # filter by species of interest
Lake %in% c("Erie", "Michigan")) %>% # filter by lakes of interest
select(Species, Lake, Year, Length_cm, Weight_g) # select, retain only these columns in filtered df
# --- Create Variables --- #
fishCSV_filt <- fishCSV_filt %>%
mutate(
Length_mm = Length_cm * 10, # create new column from base with new specification
Length_group = cut(
Length_mm, # use values from this column on which to apply cutoff/binning criteria
breaks = c(0, 200, 400, 600, Inf), # create 5 breaks = 4 bins
labels = c("≤200", "200–400", "400–600", "≥600") # name bins
)
)
length_counts <- fishCSV_filt %>%
count(Species, Length_group) # tally counts per species, newly created length grouping
# --- Summarize --- #
fishCSV_filt_summary <- fishCSV_filt %>%
group_by(Species, Year) %>% # grouping to summarize stats by multiple criteria
summarise(
mean_weight_g = mean(Weight_g, na.rm = TRUE), # new column with mean fx applied to base data
median_weight_g = median(Weight_g, na.rm = TRUE), # new colunn with median fx applied to base data
sample_size = n(), # show counts/sample size for each grouping by above criteria
.groups = "drop" # remove grouping bins from the dataframe once summaries have been caluclated
)
# --- Plot --- #
meanweight_plot <- fishCSV_filt_summary %>%
ggplot(aes(x = Year, y = mean_weight_g, color = Species)) +
geom_line() +
geom_point() +
scale_fill_brewer(palette = "Set2") +
labs(
title = "Temporal Change of Mean Weight Across Great Lakes Fish Species",
x = "Mean Weight (g)",
y = "Year") +
theme_minimal(base_size = 14) +
theme(plot.title = element_text(face = "bold", margin = margin(b = 20)),
axis.title.x = element_text(margin = margin(t = 20)),
axis.title.y = element_text(margin = margin(r = 20)),
)
print(meanweight_plot)
# --- Export --- #
write.csv(fishCSV_filt, "Outputs/fish_filtered.csv")
write.csv(fishCSV_filt_summary, "Outputs/fish_filtered_summary.csv")
write.csv(fishCSV_filt, "Outputs/length_count.csv")
###################
### OBJECTIVE 4 ###
###################
multiple_files <- list.files(path = "Data/Multiple_Files", full.names = TRUE) #List all of the files in the folder we are calling
View(multiple_files) #Viewing the files to make sure that the data was called in correctly
multiple_list <- lapply(multiple_files, read.csv) #Read the files in the Multiple_files Folder
multiple_df <- dplyr::bind_rows(multiple_list) #Combine all of the files' data into one dataframe titles "multiple_df"
View(multiple_df)
###################
### OBJECTIVE 5 ###
###################
# --- Setup: load base parallel and read the data ---#
library(parallel)
fish <- read.csv("Data/fish_bootstrap_parallel_computing.csv")
species <- unique(fish$Species)            #list of species to loop over
# --- Create Bootstrap function in Base R ---#
boot_mean <- function(species_name, n_boot = 10000, sample_size = 200) {
x <- fish$Weight_g[fish$Species == species_name] # Pull the Weigh_g vector for just this species
# n_boot = 10000 resamples WITH replacement, computing the mean each time
# sample_size = how many fish per species we want to pull
means <- replicate(n_boot, mean(sample(x, size = sample_size, replace = TRUE)))  # replicate returns a numeric vector of bootstrap means
mean(means) # Returns the average of the bootstrap means
}
# --- SERIAL ---#
t_serial <- system.time({                   # time the whole serial run
res_serial <- lapply(                     # loop over species in the main R process
species,                                # input: vector of species names
boot_mean,                              # function to apply
n_boot = 10000,                         # number of bootstrap resamples per species
sample_size = 200                       # bootstrap sample size
)
})
head(res_serial)
# --- PARALLEL --- #
n_cores <- max(1, detectCores() - 1)        # use all but one core
cl <- makeCluster(n_cores)                  # start worker processes
clusterSetRNGStream(cl, iseed = 123)        # make random numbers reproducible across workers
# Send needed objects to workers (function + data + species vector)
clusterExport(cl, varlist = c("fish", "boot_mean", "species"), envir = environment())
t_parallel <- system.time({                 # time the parallel run
res_parallel <- parLapply(                # same API as lapply(), but across workers
cl,                                     # the cluster
species,                                # each worker gets one species (or more)
boot_mean,                              # function to run
n_boot = 10000,                           # same bootstrap settings as serial
sample_size = 200
)
})
stopCluster(cl)                             #stopping the cluster when done
# --- Compare runtimes & show speedup --------------------------------------
# Extract elapsed time and compute speedup = serial / parallel
elapsed_serial   <- unname(t_serial["elapsed"])
elapsed_parallel <- unname(t_parallel["elapsed"])
speedup <- elapsed_serial / elapsed_parallel
cat("Serial elapsed (s):   ", round(elapsed_serial, 3), "\n")
cat("Parallel elapsed (s): ", round(elapsed_parallel, 3), " using ", n_cores, " cores\n", sep = "")
cat("Speedup:               ", round(speedup, 2), "x\n", sep = "")
detect cores
detectCores()
